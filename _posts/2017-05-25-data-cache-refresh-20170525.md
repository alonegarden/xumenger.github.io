---
layout: post
title: 缓存更新的套路
categories: 软件质量之内存管理 深入学习之内存管理
tags: 数据库 缓存 数据 并发 一致性 性能
---

>转载自[CoolShell：《缓存更新的套路》](http://coolshell.cn/articles/17416.html)

看到好些人在写更新缓存数据代码时，**先删除缓存，然后再更新数据库**，而后续的操作会把数据再装载到缓存中。**然而，这个逻辑是错误的**。试想，两个并发操作，一个是更新操作，一个是查询操作，更新操作删除缓存后，查询操作没有命中缓存，查询操作会先把数据库中的老数据读出来后放到缓存中，然后更新操作更新了数据库。于是，在缓存中的数据还是老的数据，导致缓存中的数据是脏的，而且一直还这样脏下去

我不知道为什么这么多人用的都是这个逻辑（注：这里先称之为Error Pattern），当我在微博上发了这个贴以后，我发现好些人给了好多非常复杂和诡异的方案，所以，我想写这篇文章说一下几个缓存更新的Design Pattern（让我们多一些套路吧）

这里，我们先不讨论更新缓存和更新数据这两个事是一个事务的事，或是会有失败的可能，我们先假设更新数据库和更新缓存都可以成功的情况（我们先把成功的代码逻辑写对）

更新缓存的Design Pattern有四种：Cache Aside、Read through、Write through、Write behind caching，我们下面一一来看这四种Pattern

## Cache Aside Pattern

这是最常用最常用的Pattern了。其具体逻辑如下：

* **失效**：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中
* **命中**：应用程序从cache中取数据，取到后返回
* **更新**：先把数据存到数据库中，成功后，再让缓存失效

![image](../media/image/2017-05-24/01.png)

![image](../media/image/2017-05-24/02.png)

注意，我们的更新是先更新数据库，成功后，让缓存失效。那么，这种方式是否可以没有文章前面提到过的那个问题呢？我们可以脑补一下

一个是查询操作，一个是更新操作的并发。首先，没有了删除cache数据的操作，而是先更新了数据库中的数据，此时，缓存依然有效，所以，并发的查询操作拿的是没有更新的数据，但是，更新操作马上让缓存的失效了，后续的查询操作再把数据从数据库中拉出来。而不会像文章开头的那个逻辑产生的问题，后续的查询操作一直都在取老的数据

这是标准的Design Pattern，包括Facebook的论文[《Scaling Memcache at Facebook》](https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf)也使用了这个策略。为什么不是写完数据库后更新缓存？你可以看一下Quora上的这个回答[《Why does Facebook use delete to remove the key-value pair in Memcached instead of updating the Memcached during write request to the backend?》](https://www.quora.com/Why-does-Facebook-use-delete-to-remove-the-key-value-pair-in-Memcached-instead-of-updating-the-Memcached-during-write-request-to-the-backend)，主要是怕两个并发的写操作导致脏数据

那么，是不是Cache Aside这个就不会有并发问题了？不是的，比如，一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以会造成脏数据

但，这个case理论上会出现，不过，实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必须在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大

**所以，这也就是Quora上的那个答案里说的，要么通过2PC或是Paxos协议保证一致性，要么就是拼命的降低并发时脏数据的概率，而Facebook使用了这个降低概率的玩法，因为2PC太慢，而Paxos太复杂。当然，最好还是为缓存设置上过期时间**

## Error Pattern和Cache Aside Pattern出问题的逻辑

对比一下最开始的策略和这个策略出现问题的逻辑场景，加深对缓存同步的理解

Error Pattern：更新操作先删缓存，再更新数据库；查询操作在缓存中没有发现数据，则从数据库中取数据并放入缓存。在下面的并发情况下会出问题：

* 更新操作删除缓存中老数据
* 查询操作没从缓存中找到数据，则从数据库中将老数据放到缓存
* 更新操作将新数据更新到数据库
* 此时数据库中是新数据，但缓存中是老数据
* 因为正常查询操作比更新操作更快，所以这种并发的交叉发生概率较高

Cache Aside Pattern：更新操作先更新数据库，再删除缓存；查询操作在缓存中没有发现数据，则从数据库中取数据并放入缓存。在下面的并发情况下会出问题：

* 查询操作没从缓存中找到，则从数据库中取老数据
* 更新操作将新数据更新到数据库，让缓存失效
* 查询操作将老数据放入缓存
* 此时数据库中是新数据，但缓存中是老数据
* 因为正常查询操作比更新操作更快，所以这种并发的交叉发生概率不高

>其区别在于查询操作更新数据库和删除缓存的顺序！

## Read/Write Through Pattern

我们可以看到，在上面的Cache Aside套路中，我们的应用代码需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）。所以，应用程序比较啰嗦。而Read/Write Through套路是把更新数据库（Repository）的操作由缓存自己代理了，所以，对于应用层来说，就简单很多了

>可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的Cache

**Read Through**

Read Through套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的

>缓存服务提供查询的接口，查询方去通过接口查询，查到最新的数据（内部实现可能是缓存服务直接从缓存中取出数据；也可能是缓存服务判断数据失效然后从数据库中加载数据更新缓存并将数据给到查询方）。所以查询方只需要调用接口即可，缓存服务内部的逻辑不需关心

**Write Through**

Write Through套路和Read Through相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）

>缓存服务提供更新的接口，更新方通过接口把数据给缓存服务实现更新（内部实现可能是缓存服务没有在缓存中找到数据，则直接更新数据库；也可能是现在缓存中找到数据，则先去更新缓存，然后缓存服务**同步**去更新数据库）

下图来自WikiPedia的[Cache词条](https://en.wikipedia.org/wiki/Cache_(computing))，其中的Memory你可以理解为就是我们例子中的数据库

![image](../media/image/2017-05-24/03.png)

## Write Behind Caching Pattern

Write Behind又叫Write Back。**一些了解Linux操作系统内核的同学对write back应该非常熟悉，这不就是Linux文件系统的Page Cache的算法吗？是的，你看基础这玩意全都是相通的**。所以，基础很重要，我已经不是一次说过基础很重要这事了

Write Back套路，一句话就是，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是让数据的IO操作飞快无比（因为直接操作内存嘛），因为异步，Write Back还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的

但是，其带来的问题是，数据不是强一致性的，而且可能会丢失（我们知道Unix/Linux非正常关机会导致数据丢失，就是因为这个事）。在软件设计上，我们基本上不可能做出没有缺陷的设计，就像算法设计中的时间换空间，空间换时间一个道理，有时候，强一致性和高性能，高可用和高性能是有冲突的。软件设计从来都是取舍Trade-Off

另外，Write Back实现逻辑比较复杂，因为它需要track有哪些数据被更新了，需要刷到持久层上。操作系统的Write Back会在仅当这个Cache需要失效的时候，才会被真正持久起来，比如，内存不够了，或是进程退出了等情况，这又叫lazy write

在wikipedia上有一张Write Back的流程图，基本流程如下

![image](../media/image/2017-05-24/04.png)

## 再多唠叨一些

1) 上面讲的这些Design Pattern，其实并不是软件架构里的MySQL数据库和memcache/redis的更新策略，这些东西都是计算机体系结构里的设计，比如CPU的缓存，硬盘文件系统中的缓存，硬盘上的缓存，数据库中的缓存。**基本上来说，这些缓存更新的设计模式都是非常老古董的，而且历经长时间考验的策略**，所以这也就是，工程学上所谓的Best Practice，遵从就好了

2) 有时候，我们觉得能做宏观的系统架构的人一定是很有经验的，其实，宏观系统架构中的很多设计都来源于这些微观的东西。比如云计算中的很多虚拟化技术的原理，和传统的虚拟内存不是很像么？Unix下的那些I/O模型，也放大到了架构里的同步异步的模型。还有Unix发明的管道不就是数据流式计算架构吗？TCP的好些设计也用在不同系统间的通讯中。仔细看看这些微观层面，你会发现有很多设计都非常精妙……所以，**请允许我在这里放句观点鲜明的话：如果你要做好架构，首先你得把计算机体系结构以及很多老古董的基础技术吃透了**

3) 在软件开发或设计中，我非常建议在之前先去参考一下已有的设计和思路，**看看相应的guideline、best practice或design pattern，吃透了已有的这些东西，再决定是否要重新发明轮子**。千万不要似是而非地，想当然的做软件设计

4) 上面，我们没有考虑缓存（Cache）和持久层（Repository）的整体事务的问题。比如，更新Cache成功，更新数据库失败了怎么办？或者反过来。关于这个事，如果你需要强一致性，你需要使用“两阶段提交协议”：prepare，commit/roolback，比如Java7的[XAResource](http://docs.oracle.com/javaee/7/api/javax/transaction/xa/XAResource.html)，还有MySQL 5.7的[XA Transaction](http://dev.mysql.com/doc/refman/5.7/en/xa.html)，有些Cache也支持XA，比如[EhCache](http://www.ehcache.org/documentation/3.0/xa.html)。当然，XA这样的强一致性的玩法会导致性能下降，关于分布式的事务的相关话题，你可以看[《分布式系统的事务处理》](http://coolshell.cn/articles/10910.html)一文
