---
layout: post
title: 使用Scrapy开发网络爬虫
categories: python之网络爬虫 python之爬虫框架
tags: mac python python2 python3 爬虫 网络爬虫 scrapy
---

## Mac搭建Python3虚拟环境

之前在[《搭建Python虚拟环境》](http://www.xumenger.com/python-environment-20160801/)、[《Python数据科学基础：Python3基础数据类型》](http://www.xumenger.com/python-data-science-01-20170109/)、[《Python数据科学基础：用Numpy、matplotlib、pandas包简单分析数据》](http://www.xumenger.com/python-data-science-02-20170109/)讲解了如何搭建Python的虚拟环境，但都是针对Python2的，接下来使用Scrapy进行的开发是基于Python3.X的，所以还是先弄一下Python3的虚拟环境

Python、virtualenv的安装不再赘言。直接执行`virtualenv _LAB3 --python=python3`创建一个虚拟环境

```
xumengerdeMacBook-Pro:Laboratory3 xumenger$ virtualenv _LAB3 --python=python3
Running virtualenv with interpreter /usr/local/bin/python3
Using base prefix '/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6'
New python executable in /Users/xumenger/Desktop/code/Laboratory3/_LAB3/bin/python3.6
Also creating executable in /Users/xumenger/Desktop/code/Laboratory3/_LAB3/bin/python
Installing setuptools, pip, wheel...done.
```

然后执行`source _LAB3/bin/activate`进入虚拟环境

```
xumengerdeMacBook-Pro:Laboratory3 xumenger$ source _LAB3/bin/activate
(_LAB3) xumengerdeMacBook-Pro:Laboratory3 xumenger$ 
```

## 安装Scrapy

如果直接使用pip安装，那么默认是Python2版本，所以执行`python3 -m pip install ...`来进行Python库的安装

先将Python3对应的pip版本进行升级

```
(_LAB3) xumengerdeMacBook-Pro:Laboratory3 xumenger$ python3 -m pip install -U pip
Requirement already up-to-date: pip in ./_LAB3/lib/python3.6/site-packages
```

然后安装对应版本的Scrapy

```
(_LAB3) xumengerdeMacBook-Pro:Laboratory3 xumenger$ python3 -m pip install scrapy==1.1.0rc3
Collecting scrapy==1.1.0rc3
  Downloading http://pypi.doubanio.com/packages/c4/33/a87d324a3c25b6e6e8018b9161987e185910bd6e611ebb75ce169a7f1312/Scrapy-1.1.0rc3-py2.py3-none-any.whl (292kB)
    100% |████████████████████████████████| 296kB 1.5MB/s 
Collecting parsel>=0.9.3 (from scrapy==1.1.0rc3)

//省略中间大量的输出

  Running setup.py bdist_wheel for pycparser ... done
  Stored in directory: /Users/xumenger/Library/Caches/pip/wheels/a6/f4/6e/87ef5d3bb2adb9040acaa5882f8643fb116c688f5499fbea8a
Successfully built PyDispatcher Twisted pycparser
Installing collected packages: six, w3lib, lxml, cssselect, parsel, idna, asn1crypto, pycparser, cffi, cryptography, pyOpenSSL, PyDispatcher, pyasn1, attrs, pyasn1-modules, service-identity, zope.interface, constantly, incremental, Automat, hyperlink, Twisted, queuelib, scrapy
Successfully installed Automat-0.6.0 PyDispatcher-2.0.5 Twisted-17.5.0 asn1crypto-0.22.0 attrs-17.2.0 cffi-1.10.0 constantly-15.1.0 cryptography-1.9 cssselect-1.0.1 hyperlink-17.2.1 idna-2.5 incremental-17.5.0 lxml-3.8.0 parsel-1.2.0 pyOpenSSL-17.0.0 pyasn1-0.2.3 pyasn1-modules-0.0.9 pycparser-2.17 queuelib-1.4.2 scrapy-1.1.0rc3 service-identity-17.0.0 six-1.10.0 w3lib-1.17.0 zope.interface-4.4.2
```

然后执行`scrapy startproject testScrapy`创建一个爬虫项目成功，说明Scrapy安装成功

```
(_LAB3) xumengerdeMacBook-Pro:Laboratory3 xumenger$ scrapy startproject testScrapy
New Scrapy project 'testScrapy', using template directory '/Users/xumenger/Desktop/code/Laboratory3/_LAB3/lib/python3.6/site-packages/scrapy/templates/project', created in:
    /Users/xumenger/Desktop/code/Laboratory3/testScrapy

You can start your first spider with:
    cd testScrapy
    scrapy genspider example example.com
(_LAB3) xumengerdeMacBook-Pro:Laboratory3 xumenger$ ls
_LAB3		testScrapy
(_LAB3) xumengerdeMacBook-Pro:Laboratory3 xumenger$ ls testScrapy/*
testScrapy/scrapy.cfg

testScrapy/testScrapy:
__init__.py	__pycache__	items.py	pipelines.py	settings.py	spiders
```

## 编写一个简单的小爬虫

上面的步骤中已经创建了一个testScrapy爬虫项目，接下来就继续这个项目，爬取我的个人网站[www.xumenge.com](www.xumenge.com)来展示Scrapy的用法


