---
layout: post
title: 大数据分布式框架
categories: 大数据技术 大型系统架构 
tags: Hadoop Apache HDFS ZooKeeper HBase Hive Pig MapReduce
---

## 分布式系统核心组件

**Hadoop**

一个分布式系统基础架构，由Apache 基金会所开发。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用**集群**的威力进行高速运算和存储

Hadoop 实现了一个分布式文件系统（Hadoop Distributed File System），简称HDFS。HDFS 有高容错性的特点，并且设计用来部署在低廉的硬件上，而且它提供高吞吐量来访问应用程序的数据，适合那些有着超大数据集的应用程序。HDFS 放宽了POSIX 的要求，可以以流的形式访问文件系统中的数据

Hadoop 的框架最核心的设计就是：HDFS 和MapReduce。HDFS 为海量的数据提供了存储，而MapReduce 为海量的数据提供了计算

**ZooKeeper**

是Hadoop 的正式子项目，它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。ZooKeeper 的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户

ZooKeeper 是Google 的Chubby 的一个开源实现，是高有效和可靠的协同工作系统，ZooKeeper 能够用来leader 选举，配置信息维护等，在一个分布式的环境中，需要一个Master 实例或存储一些配置信息，确保文件写入的一致性

ZooKeeper 是一个分布式的、开源的分布式应用程序协调服务，包含一个简单的原语集，是Hadoop 和HBase 的重要组件。提供Java 和C 的接口

**HDFS**

Hadoop 分布式文件系统（HDFS）被设计成适合运行在通用硬件上的分布式文件系统。它和现有的分布式文件系统有很多共同点。但同时，它和其他的分布式文件系统的区别也十分明显。HDFS 是一个高度容错性的系统，适合部署在廉价的机器上。HDFS 能够提供高吞吐量的数据访问，非常适合大规模数据集上的应用

HDFS 放宽了一部分POSIX 约束，来实现流式读取文件系统数据的目的。HDFS 在最开始是作为Apache Nutch 搜索引擎项目的基础框架而开发的。HDFS 是Apache Hadoop Core 项目的一部分

**HBase**

HBase 是一个分布式的、面向列的开源数据库，该技术来源于Fay Chang所撰写的Google 论文“BigTable：一个结构化数据的分布式存储系统”

就像BigTable 利用Google 文件系统所提供的分布式数据存储一样，HBase 在Hadoop 之上提供了类似于BigTable 的能力。HBase 是Apache 的Hadooop 项目的子项目。HBase 不同于一般的关系型数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase 是基于列的而不是基于行的

HBase - Hadoop Database，是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBase 基础可在廉价PC Server 上搭建起大规模结构化存储集群

**Hive + Pig**

Pig 是一种编程语言，它简化了Hadoop 常见的工作任务。Pig 可加载数据、表达转换数据以及存储最终结果。Pig 内置的操作使得半结构化数据变得有意义（比如日志文件）。同时Pig 可扩展使用Java 中添加的自定义数据类型并支持数据转换

Hive 在Hadoop 中扮演数据仓库的角色。Hive 添加数据的结构在HDFS，并允许使用类似SQL 的语法进行数据查询。与Pig 一样，Hive 的核心功能是可扩展的

Hive 更适合于数据仓库的任务，Hive 主要用于静态的结构以及经常分析的工作。Hive 与SQL 相似促使其称为Hadoop 与其他BI 工具的理想交集。Pig 赋予开发人员在大数据集领域更多的灵活性，并允许开发简洁的脚本用于转换数据流以便嵌入到较大的应用程序

Pig 相比Hive 相对轻量，它的主要优势是相比于直接使用Hadoop Java APIs 可大幅削减代码量

**本质上说说Pig 与Hive**

经过Pig Latin 的转换后变成了一道MapReduce 的作业，经过MapReduce多个线程、进程或独立系统并行执行处理的结果集进行分类和归纳。Map() 和Reduce() 两个函数会并行运行，即使不是在同一的系统的同一时刻也在同时运行一套任务，当所有的处理都完成之后，结果将被排序、格式化，并保存到一个文件。Pig 利用MapReduce 将计算分成两个阶段，第一个阶段分解成为小块并且分布到每一个存储数据的节点上进行执行，对计算的压力进行分散，第二个阶段聚合第一个阶段执行的这些结果，这样可以达到非常高的吞吐量，通过不多的代码和工作量就能驱动上千台机器进行计算，充分的利用计算机的资源，打消运行中的瓶颈

也就是说，Pig 最大的作用就是对MapReduce 算法（框架）实现了一套shell 脚本，类似于我们通常熟悉的SQL 语句，在Pig 中称之为Pig Latin，在这套脚本中我们可以对加载出来的数据进行排序、过滤、求和、分组、关联，Pig 也可以由用户自定义一些函数对数据集进行操作，这就是传说中的UDF（user-defined functions）

## 五篇论文



## 参考资料

* [Hadoop教程](https://www.yiibai.com/hadoop/)
* [Spark - 大数据Big Data处理框架](https://www.jdon.com/bigdata/spark.html)
* [用通俗易懂的大白话讲解Map/Reduce原理](https://blog.csdn.net/oppo62258801/article/details/72884633)
* [MapReduce的原理及执行过程](https://www.cnblogs.com/ahu-lichang/p/6645074.html)
* [别再比较Hadoop和Spark了，那不是设计人员的初衷](http://www.huochai.mobi/p/d/3967708/?share_tid=8b394250f453&fmid=10786192)
* [利用Docker搭建大数据处理集群](https://blog.csdn.net/iigeoxiaoyang/article/details/53020066)
* [利用docker搭建spark hadoop workbench](https://www.cnblogs.com/wanly3643/p/7919090.html)
* [Spark：超越Hadoop MapReduce](https://blog.csdn.net/javastart/article/details/70161694)
* [基于Docker快速搭建多节点Hadoop集群](http://dockone.io/article/395)
* [快速搭建docker spark+hadoop计算环境](https://blog.csdn.net/hanss2/article/details/78505446)
* [一步一步详细搭建Spark集群在docker上](https://blog.csdn.net/cq361106306/article/details/54237392)
* [Docker下安装Hadoop和Spark集群](https://blog.csdn.net/havefun00/article/details/78933723)
* [奔跑在Docker上的Spark](https://www.cnblogs.com/jasonfreak/p/5391190.html)
* [Hadoop-2.6.0+Zookeeper-3.4.6+Spark-1.5.0+Hbase-1.1.2+Hive-1.2.0集群搭建](http://blog.csdn.net/u013327467/article/details/45675705)
* [大数据学习系列之七 ----- Hadoop+Spark+Zookeeper+HBase+Hive集群搭建 图文详解](https://blog.csdn.net/qazwsxpcm/article/details/78937820)
* [大数据组件原理总结-Hadoop、Hbase、Kafka、Zookeeper、Spark](http://www.cnblogs.com/zguood/p/4609604.html)
* [一文读懂hadoop、hbase、hive、spark分布式系统架构](https://blog.csdn.net/qq_26562641/article/details/52711482)
* [Hadoop中Zookeeper，HDFS，Hbase，Hive，Pig的概念介绍与比较](https://blog.csdn.net/jiangliqing1234/article/details/39344221)
