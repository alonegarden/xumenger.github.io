---
layout: post
title: 遍历ES 索引的所有文档
categories: 大数据之elasticsearch 大数据之kibana
tags: ES ElasticSearch 分布式 搜索 游标 分页 数据分析 大数据 性能分析 Kibana 倒排索引 scroll 
---

应用的所有接口调用的日志都存放在ES 中，按日期分索引，每天新建一个索引！

现在想统计20201010～20201111 期间，所有接口trade_query 的调用，分析其输入和输出接口，所以就需要对每个索引的trade_query 接口相关的所有文档进行遍历

以下针对某一个索引为例，展示客户端的写法（如果是多个索引，遍历每个索引分别调用下面的代码逻辑即可）

## 分页查询

首先想到的是分页查询的方法，每次记录查询到的文档的位置，然后下一次查询从这个位置继续往后查询

```java
// 设置ES 集群地址
String[] clientIpList = {"192.168.28.14", "192.168.28.15", "192.168.28.16"}
HttpHost[] httpHosts = new HttpHost[clientIpList.length];
for (int i = 0; i < clientIpList.length; i++) {
    httpHosts[i] = new HttpHost(clientIpList[i], 9280, "http");
}
// 设置用户名、密码
CredentialsProvider crdPrd = new BasicCredentialsProvider();
crdPrd.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials("admin", "password1396dsgbasidw89dgossd"));
// 创建ES客户端
highLevelClient = new RestHighLevelClient(RestClient.builder(httpHosts).
                                           setHttpClientConfigCallback((HttpAsyncClientBuilder httpAsyncClientBuilder)->httpAsyncClientBuilder.setDefaultCredentialsProvider(crdPrd)));

// 每次请求200条，从第0条开始
int size = 200;
int begin = 0;
 
while (true) {
    // 指定查询RequestHead.ApiName 字段为trade_query 的文档
    BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
    boolQueryBuilder.must(QueryBuilders.matchQuery("RequestHead.ApiName", "trade_query"));

    // 指定从begin 开始，索要size 个文档
    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
    searchSourceBuilder.from(begin);
    searchSourceBuilder.size(size);
    searchSourceBuilder.timeout(new TimeValue(120, TimeUnit.SECONDS));
    searchSourceBuilder.query(boolQueryBuilder);

    // 指定具体的索引
    SearchRequest searchRequest = new SearchRequest();
    searchRequest.indices("log20201104");
    searchRequest.types("entity");
    searchRequest.source(searchSourceBuilder);
    
    // 搜索请求
    SearchResponse searchResponse = highLevelClient.search(wRequest, RequestOptions.DEFAULT);
                                    
    // 获取应答
    SearchHit[] searchHits = searchResponse.getHits().getHits();

    // 逐条处理
    int count = 0;
    for (SearchHit hit : searchHits) {
        begin ++;
        count ++;
        dealHit(hit);
    }

    // 本次循环拿到的数量小于指定要拿到的数量说明已经到最后一页了
    if (count < size) {
        break;
    }
}
```

使用这种方式查询的话，当searchSourceBuilder.from(begin) 设置的值超过10000 的时候，会出现报错

因为ElasticSearch 默认只能遍历到10000 以内的文档，如果文档数量很多，则需要针对这个索引修改其允许使用这种方式遍历的文档的数量

```json
PUT log20201101/_settings
{
  "index":{
    "max_result_window":1000000
  }
}
```

## 模糊查询

上面的代码中，构造查询条件的时候使用的是这样的方式

```java
BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
/**
 * 针对RequestHead.ApiName 字段精确查询值为trade_query 的所有文档
 */
boolQueryBuilder.must(QueryBuilders.matchQuery("RequestHead.ApiName", "trade_query"));
```

其对应在Kibana 上的表现方式是这样的

![](../media/image/2020-11-15/01.png)

![](../media/image/2020-11-15/02.png)

这个是针对索引中某个keyword 的精确匹配查询，但有时候我们想要对索引中的所有文档模糊查询的方式查询某个信息

```java
BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
/**
 * 针对索引中文档的所有字段进行模糊查询
 * 类似于在Kibana 的搜索框中搜索指定内容
 */
boolQueryBuilder.must(QueryBuilders.queryStringQuery("12386732673"))
```

其对应在Kibana 上的表现方式是这样的

![](../media/image/2020-11-15/03.png)

## 多条件查询

上面的例子是一个查询条件，但是有的时候需要多个查询条件一起过滤，比如查询某个时间段内的某个接口日志

```java
BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();

// 指定接口名
boolQueryBuilder.must(QueryBuilders.matchQuery("RequestHead.ApiName", "trade_query"));

// 指定时间范围，30分钟之前到现在
Date begin = new Date(System.currentTimeMillis() - 30 * 10 * 1000);
Date end = new Date();

SimpleDateFormat formatter = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
boolQueryBuilder.must(QueryBuilders.rangeQuery("RequestHead.ReqTime").from(formatter.format(begin)).to(formatter.format(end)));
```

对应生成的查询DSL 是这样的

```json
{
    "size": 100,
    "timeout": "120s",
    "query": {
        "bool": {
            "must": [
                {
                    "match": {
                        "RequestHead.ApiName": {
                            "query": "trade_query",
                            "operator": "OR",
                            "prefix_length": 0,
                            "max_expansions": 50,
                            "fuzzy_transpositions": true,
                            "lenient": false,
                            "zero_terms_query": "NONE",
                            "auto_generate_synonyms_phrase_query": true,
                            "boost": 1.0
                        }
                    }
                },
                {
                    "range": {
                        "RequestHead.ReqTime": {
                            "from": "2020-11-16 10:57:40",
                            "to": "2020-11-16 11:06:00",
                            "include_lower": true,
                            "include_upper": true,
                            "boost": 1.0
                        }
                    }
                }
            ],
            "adjust_pure_negative": true,
            "boost": 1.0
        }
    }
}
```

## 游标查询

但使用上面的方式“遍历”所有的文档，分析后，发现有一些应该再分析结果中的记录竟然不存在！显然漏掉了一些数据，同时再看最终分析出来的数据，还存在重复的情况

于是查阅ES 的官方文档

>[https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/index.html](https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/index.html)

>[https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high-search-scroll.html](https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high-search-scroll.html)

其推荐使用游标的方式进行查询

```java
// 设置ES 集群地址
String[] clientIpList = {"192.168.28.14", "192.168.28.15", "192.168.28.16"}
HttpHost[] httpHosts = new HttpHost[clientIpList.length];
for (int i = 0; i < clientIpList.length; i++) {
    httpHosts[i] = new HttpHost(clientIpList[i], 9280, "http");
}
// 设置用户名、密码
CredentialsProvider crdPrd = new BasicCredentialsProvider();
crdPrd.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials("admin", "password1396dsgbasidw89dgossd"));
// 创建ES客户端
highLevelClient = new RestHighLevelClient(RestClient.builder(httpHosts).
                                           setHttpClientConfigCallback((HttpAsyncClientBuilder httpAsyncClientBuilder)->httpAsyncClientBuilder.setDefaultCredentialsProvider(crdPrd)));

// 用于游标查询
final Scroll scroll = new Scroll(TimeValue.timeValueMinutes(1L));

// 指定查询RequestHead.ApiName 字段为trade_query 的文档
SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
searchSourceBuilder.query(matchQuery("RequestHead.ApiName", "trade_query"));

// 创建搜索请求
SearchRequest searchRequest = new SearchRequest();
searchRequest.indices("log20201104");
searchRequest.types("entity");
searchRequest.scroll(scroll);
searchRequest.source(searchSourceBuilder);
 
// 发起请求
SearchResponse searchResponse = highLevelClient.search(searchRequest, RequestOptions.DEFAULT); 
 
// 保留本次应答返回的scrollId，下次请求时传入该scrollId 继续查询
String scrollId = searchResponse.getScrollId();
SearchHit[] searchHits = searchResponse.getHits().getHits();

while (searchHits != null && searchHits.length > 0) { 
    
    // 这里针对每个文档进行分析
    for (SearchHit hit : searchHits)
        dealHit(hit);
    
    // 从上次返回的scrollId 继续查询
    SearchScrollRequest scrollRequest = new SearchScrollRequest(scrollId); 
    scrollRequest.scroll(scroll);
    searchResponse = highLevelClient.scroll(scrollRequest, RequestOptions.DEFAULT);
    scrollId = searchResponse.getScrollId();
    searchHits = searchResponse.getHits().getHits();
}
 
// 使用游标的方式遍历完后，“归还”游标
ClearScrollRequest clearScrollRequest = new ClearScrollRequest(); 
clearScrollRequest.addScrollId(scrollId);
ClearScrollResponse clearScrollResponse = highLevelClient.clearScroll(clearScrollRequest, RequestOptions.DEFAULT);
boolean succeeded = clearScrollResponse.isSucceeded();
```

该用这种方式之后，没有在漏数据的情况，也没有重复的情况

以log20201110 这个索引为例，该索引上一共有1800 万左右的文档，trade_query 接口相关的文档有4 万左右

使用游标的方式处理完这些文档耗时大概2min 左右！

补充另一个数据：一个索引1800 万级别的文档，一个主分片，一个副分片，分别占7.5G，共占15G

## 分页查询和游标查询对比

分页查询的原理如下

* 客户端发起请求
* 接收到请求的节点成为Coordinate Node（协调者）
* 该节点会创建一个priority queue，长度为from + size
    * 如果from = 900，size = 100
    * 本来只是想查询100 个记录
    * 但是按照上面的描述，这个请求要放900+100=1000 个记录
* Coordinate Node 将请求分发到所有的主分片或者副本分片
* 每个分片（shard）在本地创建一个同样大小的priority queue
    * 长度也是from + size
    * 用于存储该shard 执行查询的结果
* 每个shard 将各自priority queue 的元素返回给Coordinate Node
* 元素内只包含文档的ID和排序值（如_score）
* Coordinate Node 将合并所有的元素到自己的priority queue 中
* Coordinate Node 完成排序动作，最终根据from、size 对结果进行截取

```json
GET /log20201104/_search
{
  "from": 980,
  "size": 20
}
```

如果要把大批量的数据从ES 集群取出来，一次性取完肯定不合适，IO 压力过大性能容易出问题；而且越往后翻页，每次需要查询的数据就越多；假如命中条件的数据量很大，比如百万级别，越往后差priority queue 队列放的数据就越多，而且需要网络传输的数据也就越多；还有像上面案例中讲到的重复数据和丢数据的问题；分页查询又容易造成deep paging 的问题，所以推荐游标查询的方式

游标查询的原理如下

* scroll 查询先做查询初始化
* 然后再批量地拉取结果，类似数据库的cursor
* scroll 查询会取某个时间点的快照数据
* 查询初始化后，索引上的数据发生了变化，快照数据还是原来的，类似数据库的索引视图
* scroll 查询用字段_doc 排序，去掉了全局排序，性能比较高
* scroll 查询要设置过期时间，每次搜索这个时间内完成即可

先发起请求：

```json
GET /log20201104/_search?scroll=1s
{
  "size": 10
}
```

得到的应答结果如下：

```json
{
  "_scroll_id": "DnF1ZXJ5VGhlbkZldGNoBQAAAAAAABJQFkExczF1dXM3VHB1RFNpVDR4RkxPb1EAAAAAAAASUhZBMXMxdXVzN1RwdURTaVQ0eEZMT29RAAAAAAAAElMWQTFzMXV1czdUcHVEU2lUNHhGTE9vUQAAAAAAABJUFkExczF1dXM3VHB1RFNpVDR4RkxPb1EAAAAAAAASURZBMXMxdXVzN1RwdURTaVQ0eEZMT29R",
  "took": 2,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 4,
    "max_score": 1,
    ...
  }
}
```

基于本次返回的\_scroll\_id 继续请求：

```json
GET /_search/scroll
{
    "scroll": "1s", 
    "scroll_id" : "DnF1ZXJ5VGhlbkZldGNoBQAAAAAAABJQFkExczF1dXM3VHB1RFNpVDR4RkxPb1EAAAAAAAASUhZBMXMxdXVzN1RwdURTaVQ0eEZMT29RAAAAAAAAElMWQTFzMXV1czdUcHVEU2lUNHhGTE9vUQAAAAAAABJUFkExczF1dXM3VHB1RFNpVDR4RkxPb1EAAAAAAAASURZBMXMxdXVzN1RwdURTaVQ0eEZMT29R"
}
```
