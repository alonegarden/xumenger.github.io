---
layout: post
title: Spark 计算框架：Spark 架构体系
categories: 大数据之kafka 大数据之spark
tags: scala java 大数据 kafka spark MacOS 环境搭建 Scala Maven Hadoop DAG
---

>[https://www.bilibili.com/video/BV11A411L7CK?p=19](https://www.bilibili.com/video/BV11A411L7CK?p=19)

Spark 框架的核心是一个计算引擎，整体来说，它采用了标准的master-slave 的结构。下图中的Driver 表示master，负责管理整个集群中的作业任务调度，Executor 是slave，负责实际执行任务

![](../media/image/2020-11-24/01.png)

Dirver 是Spark 驱动器节点，用于执行Spark 任务中的main 方法，负责实际代码的执行工作，Driver 在Spark 作业执行时主要负责

* 将用户程序转换为作业Job
* 在Executor 之间调度任务Task
* 跟踪Executor 的执行情况
* 通过UI 展示查询运行情况

Executor 是集群中工作节点（Worker）中的一个JVM 进程，负责在Spark 作业中运行具体任务（Task），任务彼此之间相互独立。Spark 应用启动时，Executor 节点被同时启动，并且始终伴随着整个Spark 应用的生命周期而存在。如果有Executor 节点发生了故障或者崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他Executor 节点上继续运行。Executor 有两个核心功能

* 负责运行组成Spark 应用的任务，并将结果返回给驱动器进程
* 它们通过自身的块管理器（Block Manager）为用户程序中要求缓存的RDD 提供内存式存储。RDD 时候直接缓存在Executor 进程中的，因此任务可以在运行时充分利用缓存数据加速运算

Spark 集群的独立部署环境中，不需要依赖其他的资源调度框架，自身就实现了资源调度的功能，所以环境中还有其他两个核心组件：Master 与Worker

Master 是一个进程，主要负责资源的调度和分配，并进行集群的监控，类似于Yarn 环境中的RM

而Worker 也是进程，一个Worker 运行在集群中的一台服务器上，由Master 分配资源对数据进行并行的处理和计算，类似于Yarn 环境中的NM

Driver 和Executor 是和计算相关的组件，Master 和Worker 是和资源相关的组件，计算和资源如果想交互，那么就需要一个中间层来解耦，就是ApplicationMaster

Spark Executor 时集群中运行在工作节点（Worker）中的一个JVM 进程，是整个集群中的专门用于计算的节点，在提交应用中，可以提供参数指定计算节点的个数，以及对应的资源。这里的资源一般指的是工作节点Executor 的内存大小和使用的**虚拟CPU 核**（Core）数量

![](../media/image/2020-11-24/02.png)

